{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1  align=\"center\"> <b>   Facial Emotion Recongintion </b></h1>\n",
    "<h4 align=\"center\">By Sharoon Yaqub</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import models, layers\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "PATH = \"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge\"\n",
    "data = pd.read_csv(os.path.join(PATH, \"icml_face_data.csv\"))\n",
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse data into right format\n",
    "# Output: Image in right shaped and normalized + labels\n",
    "def parse_data(data):\n",
    "    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48, 1))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "# Splitting the data into train, validation and testing set thanks to Usage column\n",
    "train_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\n",
    "val_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\n",
    "test_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape\", np.shape(train_imgs))\n",
    "print(\"validation shape\", np.shape(val_imgs))\n",
    "print(\"validatio shape\", np.shape(val_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil \n",
    "os.mkdir(\"/kaggle/working/imgs\")\n",
    "data = np.array(train_imgs[:5])\n",
    "i = 0\n",
    "for px_map in data:\n",
    "    i = i + 1\n",
    "    px_map = np.reshape(px_map, (48, 48))\n",
    "    image = Image.fromarray(px_map)\n",
    "    image = image.convert('RGB')\n",
    "    image.save('/kaggle/working/imgs/'+str(i)+'.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 5\n",
    "# Define lists to store the loss and accuracy for each fold\n",
    "loss_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_test_fold = []\n",
    "accuracy_test_fold = []\n",
    "# Define the k-fold cross-validator\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list = []\n",
    "# Loop over the k folds\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_imgs, train_lbls)):\n",
    "\n",
    "    # Print the fold number\n",
    "    print(f'Fold {fold+1}/{n_splits}:')\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    x_train, y_train = train_imgs[train_indices], train_lbls[train_indices]\n",
    "    x_val, y_val = train_imgs[val_indices], train_lbls[val_indices]\n",
    "\n",
    "    # Define the CNN model\n",
    "    model_cnn = models.Sequential()\n",
    "    model_cnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(layers.Flatten())\n",
    "    model_cnn.add(layers.Dense(128, activation='relu'))\n",
    "    model_cnn.add(layers.Dropout(0.5))\n",
    "    model_cnn.add(layers.Dense(7, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model_cnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history_cnn = model_cnn.fit(x_train, y_train, epochs=20, batch_size=32,\n",
    "                            validation_data=(x_val, y_val), verbose=1)\n",
    "    \n",
    "    history_list.append(history_cnn)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    loss, accuracy = model_cnn.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {accuracy*100:.2f}%')\n",
    "    loss_per_fold.append(loss)\n",
    "    acc_per_fold.append(accuracy*100)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss_test, accuracy_test = model_cnn.evaluate(test_imgs, test_lbls, verbose=0)\n",
    "    print(f'Test accuracy: {accuracy_test*100:.2f}%')\n",
    "    loss_test_fold.append(loss_test)\n",
    "    accuracy_test_fold.append(accuracy_test*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the metric values from all histories\n",
    "metric_values = []\n",
    "for history in history_list:\n",
    "    metric_values.append(history.history['val_accuracy'])\n",
    "\n",
    "# Calculate mean and standard deviation of the metric\n",
    "mean_metric = np.mean(metric_values)\n",
    "std_metric = np.std(metric_values)\n",
    "\n",
    "print(\"Mean metric value:\", mean_metric)\n",
    "print(\"Standard deviation of metric:\", std_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation accuracy vs. epoch\n",
    "train_acc = history_cnn.history['accuracy']\n",
    "val_acc = history_cnn.history['val_accuracy']\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Train and validation loss vs. epoch\n",
    "train_loss = history_cnn.history['loss']\n",
    "val_loss = history_cnn.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set\n",
    "y_pred = model_cnn.predict_classes(test_imgs)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(test_lbls, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(emotions))\n",
    "plt.xticks(tick_marks, emotions.values(), rotation=45)\n",
    "plt.yticks(tick_marks, emotions.values())\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "matr, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                show_normed=True,\n",
    "                                show_absolute=False,\n",
    "                                class_names=emotions.values(),\n",
    "                                figsize=(8, 8))\n",
    "matr.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
